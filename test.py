from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import numpy as np
import torch
import json
from progress.bar import Bar
import matplotlib.pyplot as plt
import matplotlib  # 确保在无头服务器上正常工作

matplotlib.use('Agg')

from lib.utils.opts import opts
from lib.models.stNet import get_det_net, load_model
from lib.dataset.coco import COCO as CustomDataset
from lib.utils.decode import ctdet_decode
from lib.utils.post_process import ctdet_post_process
from evaluator import DetectionEvaluator


# --- 辅助函数 (保持不变) ---
def process(model, image, opt):
    with torch.no_grad():
        output = model(image)[-1]
        hm = output['hm'].sigmoid_()
        wh = output['wh']
        reg = output.get('reg', None)
        dets = ctdet_decode(hm, wh, reg=reg, K=opt.K)
    return dets


def post_process(dets, meta, num_classes):
    dets = dets.detach().cpu().numpy().reshape(1, -1, dets.shape[2])

    # ==================== [核心修复 1: 还原此函数] ====================
    # 此函数的作用是将坐标从输出特征图(out_height, out_width)
    # 还原到被送入模型的图像(即resize后的图像)的坐标系中。
    # 因此，这里必须使用 meta['out_height'] 和 meta['out_width']。
    dets = ctdet_post_process(
        dets.copy(), [meta['c']], [meta['s']],
        meta['out_height'], meta['out_width'], num_classes)
    # =================================================================

    for j in range(1, num_classes + 1):
        if len(dets[0][j]) > 0:
            dets[0][j] = np.array(dets[0][j], dtype=np.float32).reshape(-1, 5)
        else:
            dets[0][j] = np.empty([0, 5], dtype=np.float32)
    return dets[0]


def save_predictions_as_yolo(predictions, resized_shape, original_img_shape, save_path, coco_id_to_yolo_id_map):
    """
    将检测结果保存为YOLO .txt格式。
    新增了从resize后的坐标系到原始坐标系的缩放步骤。
    """
    resized_h, resized_w = resized_shape
    original_h, original_w = original_img_shape

    # 计算从resize尺寸到原始尺寸的缩放比例
    scale_w = original_w / resized_w
    scale_h = original_h / resized_h

    with open(save_path, 'w') as f:
        for coco_cls_id in predictions:
            yolo_cls_id = coco_id_to_yolo_id_map.get(coco_cls_id)
            if yolo_cls_id is None: continue

            for bbox in predictions[coco_cls_id]:
                score = bbox[4]
                # bbox[:4] 的坐标是基于 resized_shape (例如 640x512)
                x1_resized, y1_resized, x2_resized, y2_resized = bbox[:4]

                # ==================== [核心修复 2: 线性缩放坐标] ====================
                # 将坐标从resize后的空间线性缩放到原始图像空间
                x1_orig = x1_resized * scale_w
                y1_orig = y1_resized * scale_h
                x2_orig = x2_resized * scale_w
                y2_orig = y2_resized * scale_h
                # ===================================================================

                # 使用原始尺寸进行clip和归一化
                x1, x2 = np.clip([x1_orig, x2_orig], 0, original_w - 1)
                y1, y2 = np.clip([y1_orig, y2_orig], 0, original_h - 1)

                box_w, box_h = x2 - x1, y2 - y1

                # 确保宽度和高度有效
                if box_w <= 0 or box_h <= 0:
                    continue

                center_x, center_y = x1 + box_w / 2, y1 + box_h / 2

                # 使用原始尺寸进行归一化
                center_x_norm = center_x / original_w
                w_norm = box_w / original_w
                center_y_norm = center_y / original_h
                h_norm = box_h / original_h

                f.write(
                    f"{yolo_cls_id} {center_x_norm:.6f} {center_y_norm:.6f} {w_norm:.6f} {h_norm:.6f} {score:.6f}\n")


# --- 评估主函数 ---
def test_and_evaluate_multi_confidence(opt, modelPath):
    os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpus_str
    opt.device = torch.device('cuda' if opt.gpus[0] >= 0 else 'cpu')

    print(f"📍 Model path: {modelPath}\nModel: {opt.model_name}")

    dataset = CustomDataset(opt, 'test')
    data_loader = torch.utils.data.DataLoader(
        dataset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)

    model = get_det_net({'hm': dataset.num_classes, 'wh': 2, 'reg': 2}, opt.model_name)
    print(f"Loading model from: {modelPath}")
    model = load_model(model, modelPath)
    model = model.to(opt.device)
    model.eval()

    # [修正] 创建健壮的类别映射
    coco_id_to_yolo_id = dataset.cat_ids  # {coco_id: yolo_id}
    class_names_list = dataset.class_name[1:]  # 假设第一个是 __background__

    # --- 2. 推理阶段 ---
    model_file_name = os.path.splitext(os.path.basename(modelPath))[0]
    pred_root_dir = os.path.join('./results', f'{opt.model_name}_{model_file_name}', 'yolo_predictions_raw')
    os.makedirs(pred_root_dir, exist_ok=True)
    print(f"Raw predictions (conf=0.0) will be saved to: {pred_root_dir}")

    bar = Bar(f'🚀 Inference Phase', max=len(data_loader))
    for ind, (img_id, batch) in enumerate(data_loader):
        image = batch['input'].to(opt.device)
        meta = batch['meta']
        meta = {k: v.numpy()[0] for k, v in meta.items()}

        # 1. 获取原始图像尺寸
        original_h, original_w = meta['original_height'], meta['original_width']

        # 2. 获取resize后的图像尺寸 (从输入tensor的shape中获取)
        resized_h, resized_w = image.shape[3], image.shape[4]

        file_rel_path = dataset.coco.loadImgs(ids=[img_id.item()])[0]['file_name']

        dets_raw = process(model, image, opt)

        # post_process会将坐标还原到 resized 尺寸 (例如 640x512)
        dets = post_process(dets_raw, meta, dataset.num_classes)

        # ... (构建保存路径的代码) ...
        path_parts = file_rel_path.replace('\\', '/').split('/')
        video_name = path_parts[-2] if len(path_parts) > 1 else 'video_root'
        frame_name_no_ext = os.path.splitext(os.path.basename(file_rel_path))[0]
        save_video_dir = os.path.join(pred_root_dir, video_name)
        os.makedirs(save_video_dir, exist_ok=True)
        save_path = os.path.join(save_video_dir, frame_name_no_ext + '.txt')

        # ==================== [核心修复 3: 更新函数调用] ====================
        # 传入 resized 尺寸和 original 尺寸
        save_predictions_as_yolo(
            predictions=dets,
            resized_shape=(resized_h, resized_w),
            original_img_shape=(original_h, original_w),
            save_path=save_path,
            coco_id_to_yolo_id_map=coco_id_to_yolo_id
        )
        # ===================================================================

        bar.next()
    bar.finish()
    print(f"✅ Inference complete!")

    # --- 3. 多置信度评估 ---
    confidence_thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.275, 0.3, 0.325, 0.35, 0.4, ]
    results_summary = {}

    print("\n📊 Starting multi-confidence evaluation...")
    for i, conf in enumerate(confidence_thresholds):
        print(f"🎯 Evaluating confidence threshold {i + 1}/{len(confidence_thresholds)}: {conf:.2f}")

        filtered_pred_root_dir = os.path.join('./results', f'{opt.model_name}_{model_file_name}',
                                              f'filtered_preds_conf_{conf:.2f}')
        os.makedirs(filtered_pred_root_dir, exist_ok=True)

        # 过滤预测文件
        for video_name in os.listdir(pred_root_dir):
            src_video_dir = os.path.join(pred_root_dir, video_name)
            if not os.path.isdir(src_video_dir): continue
            dst_video_dir = os.path.join(filtered_pred_root_dir, video_name)
            os.makedirs(dst_video_dir, exist_ok=True)
            for fname in os.listdir(src_video_dir):
                src_file_path = os.path.join(src_video_dir, fname)
                if not os.path.isfile(src_file_path): continue  # 跳过子目录
                with open(src_file_path, 'r') as f_in, open(os.path.join(dst_video_dir, fname), 'w') as f_out:
                    for line in f_in:
                        if float(line.strip().split()[-1]) >= conf: f_out.write(line)

        eval_config = {
            'gt_root': os.path.join(opt.data_dir, 'labels'),  # 假设GT是YOLO格式
            'pred_root': filtered_pred_root_dir,
            'iou_threshold': opt.iou_thresh,
            'class_names': class_names_list,
        }
        evaluator = DetectionEvaluator(eval_config)
        evaluator.evaluate_all()
        overall_metrics = evaluator.calculate_overall_metrics()

        if 'overall' in overall_metrics:
            metrics = overall_metrics['overall']
            results_summary[conf] = {
                'recall': metrics['recall'], 'precision': metrics['precision'], 'f1': metrics.get('f1', 0.0),
                'false_alarm_rate': metrics['false_alarm_rate'],
                'spatiotemporal_stability': metrics['spatiotemporal_stability'],
                'tp': metrics['tp'], 'fp': metrics['fp'], 'fn': metrics['fn']
            }
        else:
            results_summary[conf] = {'recall': 0, 'precision': 0, 'f1': 0, 'false_alarm_rate': 1.0,
                                     'spatiotemporal_stability': 0.0, 'tp': 0, 'fp': 0, 'fn': 0}

    print("✅ Evaluation complete!")
    return results_summary


# --- [绘图和主执行块] ---
def save_and_plot_results(results, model_name, model_path):
    model_file_name = os.path.splitext(os.path.basename(model_path))[0]
    output_dir = os.path.join('./confidence_analysis_results', f'{model_name}_{model_file_name}')
    os.makedirs(output_dir, exist_ok=True)

    json_path = os.path.join(output_dir, 'confidence_analysis.json')
    with open(json_path, 'w') as f: json.dump(results, f, indent=2)
    print(f"📁 Full results saved to: {json_path}")

    thresholds = sorted(results.keys())
    if len(thresholds) < 1: return

    recalls = [results[t]['recall'] for t in thresholds]
    fars = [results[t]['false_alarm_rate'] for t in thresholds]

    fig, ax1 = plt.subplots(figsize=(10, 6))
    color = 'tab:blue'
    ax1.set_xlabel('Confidence Threshold');
    ax1.set_ylabel('Recall', color=color)
    ax1.plot(thresholds, recalls, marker='o', color=color, label='Recall')
    ax1.tick_params(axis='y', labelcolor=color);
    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)
    ax1.set_ylim([0, max(1.0, max(recalls) * 1.1 if recalls else 1.0)])

    ax2 = ax1.twinx()
    color = 'tab:red'
    ax2.set_ylabel('False Alarm Rate', color=color)
    ax2.plot(thresholds, fars, marker='s', linestyle='--', color=color, label='False Alarm Rate')
    ax2.tick_params(axis='y', labelcolor=color)
    ax2.set_ylim([0, max(1.0, max(fars) * 1.1 if fars else 1.0)])

    fig.suptitle('Recall and False Alarm Rate vs. Confidence Threshold', fontsize=16)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    lines, labels = ax1.get_legend_handles_labels();
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines + lines2, labels + labels2, loc='best')

    plot_path = os.path.join(output_dir, 'Recall_FAR_vs_Confidence.png')
    plt.savefig(plot_path)
    print(f"📈 Performance curves saved to: {plot_path}")


if __name__ == '__main__':
    opt = opts().parse()

    if opt.load_model == '':
        modelPath = './checkpoint/DSFNet.pth'
    else:
        modelPath = opt.load_model

    results_summary = test_and_evaluate_multi_confidence(opt, modelPath)

    if results_summary:
        print("\n" + "=" * 95)
        print("📊 Confidence Threshold Performance Summary")
        print("=" * 95)
        print(
            f"{'Conf.':<6} {'Recall':<10} {'Precision':<10} {'FAR':<10} {'Stability':<12} {'TP':<8} {'FP':<8} {'FN':<8}")
        print("-" * 95)
        for conf, metrics in sorted(results_summary.items()):
            print(f"{conf:<6.1f} {metrics['recall']:<10.4f} {metrics['precision']:<10.4f} "
                  f"{metrics['false_alarm_rate']:<10.4f} {metrics['spatiotemporal_stability']:<12.4f} "
                  f"{metrics['tp']:<8} {metrics['fp']:<8} {metrics['fn']:<8}")
        print("=" * 95)
        save_and_plot_results(results_summary, opt.model_name, modelPath)

    print("\n✅ Multi-confidence evaluation finished!")